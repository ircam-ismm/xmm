XMM — Probabilistic Models for Continuous Motion Recognition and Mapping
===========================================

XMM is a portable, cross-platform C++ library that implements Gaussian Mixture Models and Hidden Markov Models for recognition and regression. The XMM library was developed for movement interaction in creative applications and implements an interactive machine learning workflow with fast training and continuous, real-time inference.

### Major Update! [Sept. 2016]

We just updated XMM to the newest API version!

This version is not compatible with the initial API, which is still available on a separate branch: https://github.com/Ircam-RnD/xmm/tree/v0-historic-api.

### Contact

Jules Francoise: <jules.francoise@ircam.fr>

### author

This code has been initially authored by <a href="http://julesfrancoise.com">Jules Francoise</a> during his PhD thesis, supervised by <a href="frederic-bevilacqua.net">Frederic Bevilacqua</a>, in the <a href="http://ismm.ircam.fr">Sound Music Movement Interaction</a> team of the <a href="http://www.ircam.fr/stms.html?&L=1">STMS Lab</a> - IRCAM - CNRS - UPMC (2011-2015).

### Copyright

Copyright (C) 2015 UPMC, Ircam-Centre Pompidou.

### Licence

This project is released under the <a href="http://www.gnu.org/licenses/gpl-3.0.en.html">GPLv3</a> license.
For commercial applications, a proprietary license is available upon request to Frederick Rousseau <frederick.rousseau@ircam.fr>.

XMM is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

XMM is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with XMM.  If not, see <http://www.gnu.org/licenses/>.

### Citing this work

If you use this code for research purposes, please cite one of the following publications:

- J. Francoise, N. Schnell, R. Borghesi, and F. Bevilacqua, Probabilistic Models for Designing Motion and Sound Relationships. In Proceedings of the 2014 International Conference on New Interfaces for Musical Expression, NIME’14, London, UK, 2014.
- J. Francoise, N. Schnell, and F. Bevilacqua, A Multimodal Probabilistic Model for Gesture-based Control of Sound Synthesis. In Proceedings of the 21st ACM international conference on Multimedia (MM’13), Barcelona, Spain, 2013.

### Dependencies

 The library depends on <a href="https://github.com/open-source-parsers/jsoncpp">jsoncpp</a> for JSON file I/O. The library is distributed with this softare. The units tests rely on the <a href="https://github.com/philsquared/Catch">Catch</a> testing framework

## Documentation

The full documentation is available on Github Pages: http://ircam-ismm.github.io/xmm/
